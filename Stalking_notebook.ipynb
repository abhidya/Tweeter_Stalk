{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robobrowser import RoboBrowser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from geotext import GeoText\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "import json as json\n",
    "\n",
    "class twitter_stalker:\n",
    "    \n",
    "    def __init__(self ):\n",
    "\n",
    "        self.HEADERS_LIST = [\n",
    "        'Mozilla/5.0 (Windows; U; Windows NT 6.1; x64; fr; rv:1.9.2.13) Gecko/20101203 Firebird/3.6.13',\n",
    "        'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko',\n",
    "        'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "        'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "        'Mozilla/5.0 (Windows NT 5.2; RW; rv:7.0a1) Gecko/20091211 SeaMonkey/9.23a1pre'\n",
    "        ]\n",
    "        self.session = requests.Session()\n",
    "        self.browser = RoboBrowser(session=self.session, user_agent=random.choice(self.HEADERS_LIST))\n",
    "        self.handle = ''\n",
    "        self.id_url = \"https://twitter.com/intent/user?user_id=\"\n",
    "        self.prof_url = \"https://twitter.com/\"\n",
    "        self.TWITTER_AUTH = tweepy.OAuthHandler(\n",
    "            \"\",\n",
    "            \"\"\n",
    "        )\n",
    "        self.TWITTER_AUTH.set_access_token(\n",
    "            \"\",\n",
    "            \"\"\n",
    "        )\n",
    "        self.api = tweepy.API(self.TWITTER_AUTH, parser = tweepy.parsers.JSONParser(), wait_on_rate_limit = True, wait_on_rate_limit_notify = True, compression=True)\n",
    "\n",
    "    def get_ids(self, user):\n",
    "        followers = []\n",
    "        p = self.api.followers_ids(user)\n",
    "        followers.extend(p['ids'])\n",
    "        return followers\n",
    "    \n",
    "    def get_id(self, user):\n",
    "        p = boi.api.get_user(\"sydshelby\")\n",
    "        if p == None:\n",
    "            print(\"Couldn't get user ID from user_name\")\n",
    "            return None\n",
    "        return p['id']\n",
    "\n",
    "    def get_handle(self, id):  # Takes an id number and returns screenname\n",
    "        url = self.id_url+str(id)\n",
    "        self.browser.open(url)\n",
    "        results = self.browser.find_all(\"span\", {\"class\": \"nickname\"})\n",
    "        try:\n",
    "            handle = (\" \".join(str(results[0].text).split()))\n",
    "            return handle\n",
    "        except (IndexError):\n",
    "            return None\n",
    "\n",
    "    def get_loc(self, screen_name): # takes a screen name and tries to return location from bio\n",
    "        url = \"https://twitter.com/\" + str(screen_name) \n",
    "        self.browser.open(url)\n",
    "        try:\n",
    "            results = self.browser.find_all(\"span\", {\"class\": \"ProfileHeaderCard-locationText u-dir\"})\n",
    "            handle = (\" \".join(str(results[0].text).split()))\n",
    "            if handle.isspace() or handle == None or not handle:\n",
    "                return None\n",
    "            return (\" \".join(str(results[0].text).split()))\n",
    "        except (IndexError):\n",
    "            return None\n",
    "        \n",
    "    def normalize_cities(self, document):\n",
    "        places = GeoText(document)\n",
    "        try:\n",
    "            return places.cities[0]\n",
    "        except IndexError:\n",
    "            return None\n",
    "        \n",
    "    def lower_bois(self, document):\n",
    "        return document.lower()\n",
    "    \n",
    "    def get_long_lang(self, document):\n",
    "        geolocator = Nominatim(user_agent='myapplication')\n",
    "        location = geolocator.geocode(document)\n",
    "        try:\n",
    "            return str(location.raw['lon']),str(location.raw['lat'])\n",
    "        except (IndexError, AttributeError):\n",
    "            return None, None\n",
    "        \n",
    "        \n",
    "    def find_location(self, document):\n",
    "        handle = None\n",
    "        location  = None\n",
    "        user_id = None\n",
    "        if isinstance(document, int):\n",
    "            handle = self.get_handle(document)\n",
    "            user_id = document\n",
    "            if handle == None:\n",
    "                print(\"Couldn't Retrieve Handle through ID, Check ID\")\n",
    "                return\n",
    "            \n",
    "        if isinstance(document, str):\n",
    "            handle = document\n",
    "        \n",
    "        location = self.get_loc(handle)\n",
    "        if location != None:\n",
    "            std_location = self.normalize_cities(location)\n",
    "            if std_location == None:\n",
    "                print(\"Couldn't Standardize\")\n",
    "                return location\n",
    "            \n",
    "        if location == None and user_id != None:\n",
    "            return self.process_dict(self.get_id_location(self.get_ids(user_id), 400))\n",
    "        \n",
    "        if location == None and user_id == None:\n",
    "            user_id = self.get_id(handle)\n",
    "            if user_id != None:\n",
    "                return self.process_dict(self.get_id_location(self.get_ids(user_id), 400))\n",
    "            return None\n",
    "\n",
    "    def get_people(self, link, handle):\n",
    "        session = requests.Session()\n",
    "        people_list = []\n",
    "        browser = RoboBrowser(session=session, user_agent=random.choice(self.HEADERS_LIST), parser=\"lxml\")\n",
    "        url = \"https://twitter.com\" + link\n",
    "        try:\n",
    "            browser.open(url)\n",
    "            results = browser.find_all(\"a\", {\n",
    "                \"class\": \"account-group js-account-group js-action-profile js-user-profile-link js-nav\"})\n",
    "            for link in results:\n",
    "                people_list.append(str(link.get('href')).replace(\"/\", \"\"))\n",
    "        except:\n",
    "            pass\n",
    "        return people_list\n",
    "\n",
    "    def get_tweets(self, handle, max_position=None):\n",
    "        session = requests.Session()\n",
    "        browser = RoboBrowser(session=session, user_agent=random.choice(self.HEADERS_LIST), parser=\"lxml\")\n",
    "\n",
    "        url = \"https://twitter.com/i/profiles/show/\" + handle + \"/timeline/tweets?include_available_features=false&include_entities=false&reset_error_state=false\"\n",
    "        if max_position != None:\n",
    "            url = url + \"&\" + \"max_position=\" + max_position\n",
    "        browser.open(url)\n",
    "        result = json.loads(browser.response.content)\n",
    "        min_position = result['min_position']\n",
    "        soup = BeautifulSoup(result['items_html'], 'lxml')\n",
    "        links = []\n",
    "        for link in soup.find_all('a'):\n",
    "            if str(\"/\" + handle + \"/status/\").lower() in str(link).lower():\n",
    "                links.append(link.get('href'))\n",
    "        return min_position, links\n",
    "\n",
    "\n",
    "    def duplicates(self, duplicate): \n",
    "        final_list = [] \n",
    "        for num in duplicate: \n",
    "            if num not in final_list: \n",
    "                final_list.append(num) \n",
    "        return final_list \n",
    "    \n",
    "    def Non_Tweep_friends(self, handle):\n",
    "        min_position, links = self.get_tweets(handle)\n",
    "        while (True):\n",
    "            min_position1, links1 = self.get_tweets(handle, min_position)\n",
    "            links = links + links1\n",
    "            if (min_position1 == None):\n",
    "                break\n",
    "            min_position = min_position1\n",
    "\n",
    "        people_list = []\n",
    "\n",
    "        for link in tqdm(links):\n",
    "            if handle in link:\n",
    "                people_list = people_list + self.get_people(link, handle)\n",
    "                people_list = self.duplicates(people_list)\n",
    "            people_list = self.duplicates(people_list)\n",
    "\n",
    "        return(people_list)\n",
    "        \n",
    "    def get_id_location(self, followers_ids, amount): #takes list of follower ids returns dict of location frequencies\n",
    "        locations = {}\n",
    "        j = 0\n",
    "        for i in tqdm(followers_ids):\n",
    "            place = self.get_handle(str(i))\n",
    "            if(place == None):\n",
    "                continue\n",
    "            place = self.get_loc(place)\n",
    "            \n",
    "            if(place == None):\n",
    "                continue    \n",
    "            if place not in locations:\n",
    "                locations[place] = 0\n",
    "            locations[place]  = locations[place] +1\n",
    "            j = j+1\n",
    "            if (j>amount):\n",
    "                break\n",
    "        return locations\n",
    "    \n",
    "    def get_followers_location(self, followers_ids, amount): #takes list of screen names returns dict of location counts\n",
    "        locations = {}\n",
    "        j = 0\n",
    "        for i in tqdm(followers_ids):\n",
    "            place = self.get_loc(i)\n",
    "            if(place == None):\n",
    "                continue    \n",
    "            if place not in locations:\n",
    "                locations[place] = 0\n",
    "            locations[place]  = locations[place] +1\n",
    "            j = j+1\n",
    "            if (j>amount):\n",
    "                break\n",
    "        return locations\n",
    "\n",
    "    def process_dict(self, locations):\n",
    "        s = pd.Series(locations, name='Counts')\n",
    "        s.index.name = 'Locations'\n",
    "        s = s.reset_index()\n",
    "        #s = s[s.Counts > 1]\n",
    "        s = s[s.Locations != '']\n",
    "        s[\"norm_locations\"] = s.Locations.apply(self.normalize_cities)\n",
    "        s[\"norm_locations\"].fillna(s.Locations, inplace=True) \n",
    "        s[\"norm_locations\"] = s[\"norm_locations\"].apply(self.lower_bois)\n",
    "        s = s.groupby(s.norm_locations).sum()\n",
    "        s.sort_values(by=['Counts'])\n",
    "        s = s.reset_index()\n",
    "        s[\"longlat\"] = s.norm_locations.apply(self.get_long_lang)\n",
    "        s['long'] = s['longlat'].str[0]\n",
    "        s['lat'] = s['longlat'].str[1]\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a10ac90f6f4d9b8af265c7ab203e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=413), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['SydShelby', 'EerieEnchilada', 'graysobstory', 'too_gruntt', 'mary41911192', 'mj111897', 'caitlinll42', 'jere594', 'rottencity8790', 'bugbear73043215', 'yad2rebos', 'PanchosAR', 'SkyGravit75']\n"
     ]
    }
   ],
   "source": [
    "boi = twitter_stalker()\n",
    "\n",
    "syds_activity = boi.Non_Tweep_friends(\"SydShelby\")\n",
    "print(syds_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9cf530808a4742ae9eae2e9064a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manny/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/manny/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = boi.get_followers_location(syds_activity, len(syds_activity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manny/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/manny/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30004997093a4f13a198366364e5f716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=199), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "syd = boi.find_location(\"SydShelby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   norm_locations  Counts                    longlat         long         lat\n",
      "0       knoxville      23  (-83.9210261, 35.9603948)  -83.9210261  35.9603948\n",
      "1         memphis      27  (-90.0516285, 35.1490215)  -90.0516285  35.1490215\n",
      "2  tennessee, usa       5  (-86.2820081, 35.7730076)  -86.2820081  35.7730076\n"
     ]
    }
   ],
   "source": [
    "print(syd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              norm_locations  Counts                           longlat  \\\n",
      "0                        901       1           (21.6783608, 44.072744)   \n",
      "1  a red dot in a blue state       1                      (None, None)   \n",
      "2                    atlanta       1         (-84.3901849, 33.7490987)   \n",
      "3                chattanooga       1         (-85.3096801, 35.0456297)   \n",
      "4                  knoxville       1         (-83.9210261, 35.9603948)   \n",
      "5                    memphis       2         (-90.0516285, 35.1490215)   \n",
      "6     mississippi gulf coast       1  (-89.1358381840008, 30.35120185)   \n",
      "7               west memphis       1         (-90.1845388, 35.1464797)   \n",
      "\n",
      "                long          lat  \n",
      "0         21.6783608    44.072744  \n",
      "1               None         None  \n",
      "2        -84.3901849   33.7490987  \n",
      "3        -85.3096801   35.0456297  \n",
      "4        -83.9210261   35.9603948  \n",
      "5        -90.0516285   35.1490215  \n",
      "6  -89.1358381840008  30.35120185  \n",
      "7        -90.1845388   35.1464797  \n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
